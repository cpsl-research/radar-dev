{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9591a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot import rss library -- don't worry about this unless you need 'safety' evals\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import avapi\n",
    "import avstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3fc034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot find CAN bus data\n",
      "WARNING:root:Cannot find CAN bus data\n"
     ]
    }
   ],
   "source": [
    "nusc_data_dir = '/data/nuScenes'\n",
    "NSM = avapi.nuscenes.nuScenesManager(nusc_data_dir)\n",
    "NSD = NSM.get_scene_dataset_by_name('scene-0103')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77b852",
   "metadata": {},
   "source": [
    "## Test Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387c7f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'speed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m frame \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m img \u001b[39m=\u001b[39m NSD\u001b[39m.\u001b[39;49mget_image(frame, \u001b[39m'\u001b[39;49m\u001b[39mmain_camera\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m pc \u001b[39m=\u001b[39m NSD\u001b[39m.\u001b[39mget_lidar(frame, \u001b[39m'\u001b[39m\u001b[39mmain_lidar\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m objects \u001b[39m=\u001b[39m NSD\u001b[39m.\u001b[39mget_objects(frame, \u001b[39m'\u001b[39m\u001b[39mmain_lidar\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/radar-dev/submodules/lib-avstack-api/avapi/_dataset.py:150\u001b[0m, in \u001b[0;36mBaseSceneDataset.get_image\u001b[0;34m(self, frame, sensor)\u001b[0m\n\u001b[1;32m    148\u001b[0m cam_string \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimage-\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m sensor \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(sensor, \u001b[39mint\u001b[39m) \u001b[39melse\u001b[39;00m sensor\n\u001b[1;32m    149\u001b[0m cam_string \u001b[39m=\u001b[39m cam_string \u001b[39mif\u001b[39;00m sensor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msensor_name(frame)\n\u001b[0;32m--> 150\u001b[0m calib \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_calibration(frame, cam_string)\n\u001b[1;32m    151\u001b[0m \u001b[39mreturn\u001b[39;00m sensors\u001b[39m.\u001b[39mImageData(\n\u001b[1;32m    152\u001b[0m     ts, frame, data, calib, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sensor_ID(cam_string), channel_order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/radar-dev/submodules/lib-avstack-api/avapi/_dataset.py:135\u001b[0m, in \u001b[0;36mBaseSceneDataset.get_calibration\u001b[0;34m(self, frame, sensor)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_calibration\u001b[39m(\u001b[39mself\u001b[39m, frame, sensor):\n\u001b[1;32m    134\u001b[0m     sensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sensor_name(sensor)\n\u001b[0;32m--> 135\u001b[0m     ego_reference \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_ego_reference(frame)\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_calibration(frame, sensor\u001b[39m=\u001b[39msensor, ego_reference\u001b[39m=\u001b[39mego_reference)\n",
      "File \u001b[0;32m~/Documents/radar-dev/submodules/lib-avstack-api/avapi/_dataset.py:142\u001b[0m, in \u001b[0;36mBaseSceneDataset.get_ego_reference\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_ego_reference\u001b[39m(\u001b[39mself\u001b[39m, frame):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_ego(frame)\u001b[39m.\u001b[39mas_reference()\n",
      "File \u001b[0;32m~/Documents/radar-dev/submodules/lib-avstack-api/avapi/_dataset.py:139\u001b[0m, in \u001b[0;36mBaseSceneDataset.get_ego\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_ego\u001b[39m(\u001b[39mself\u001b[39m, frame):\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_ego(frame)\n",
      "File \u001b[0;32m~/Documents/radar-dev/submodules/lib-avstack-api/avapi/_dataset.py:681\u001b[0m, in \u001b[0;36m_nuBaseDataset._load_ego\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    679\u001b[0m q_G_to_E \u001b[39m=\u001b[39m Attitude(np\u001b[39m.\u001b[39mquaternion(\u001b[39m*\u001b[39mego[\u001b[39m\"\u001b[39m\u001b[39mrotation\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mconjugate(), ref)\n\u001b[1;32m    680\u001b[0m q_E_to_G \u001b[39m=\u001b[39m q_G_to_E\u001b[39m.\u001b[39mconjugate()\n\u001b[0;32m--> 681\u001b[0m v_in_G \u001b[39m=\u001b[39m Velocity(ego[\u001b[39m\"\u001b[39;49m\u001b[39mspeed\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m*\u001b[39m q_E_to_G\u001b[39m.\u001b[39mforward_vector, ref)\n\u001b[1;32m    682\u001b[0m acc_in_G \u001b[39m=\u001b[39m Acceleration(\n\u001b[1;32m    683\u001b[0m     q_mult_vec(q_E_to_G\u001b[39m.\u001b[39mq, np\u001b[39m.\u001b[39marray(ego[\u001b[39m\"\u001b[39m\u001b[39macceleration\u001b[39m\u001b[39m\"\u001b[39m])), ref\n\u001b[1;32m    684\u001b[0m )\n\u001b[1;32m    685\u001b[0m ang_in_G \u001b[39m=\u001b[39m AngularVelocity(\n\u001b[1;32m    686\u001b[0m     np\u001b[39m.\u001b[39mquaternion(\u001b[39m*\u001b[39mq_mult_vec(q_E_to_G\u001b[39m.\u001b[39mq, np\u001b[39m.\u001b[39marray(ego[\u001b[39m\"\u001b[39m\u001b[39mrotation_rate\u001b[39m\u001b[39m\"\u001b[39m]))),\n\u001b[1;32m    687\u001b[0m     ref,\n\u001b[1;32m    688\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'speed'"
     ]
    }
   ],
   "source": [
    "frame = 20\n",
    "img = NSD.get_image(frame, 'main_camera')\n",
    "pc = NSD.get_lidar(frame, 'main_lidar')\n",
    "objects = NSD.get_objects(frame, 'main_lidar')\n",
    "\n",
    "# -- 2d camera\n",
    "avapi.visualize.snapshot.show_image_with_boxes(img, objects, inline=True)\n",
    "\n",
    "# -- 2d bev\n",
    "vectors = [obj.velocity_head_tail for obj in objects]\n",
    "avapi.visualize.snapshot.show_lidar_bev_with_boxes(pc, boxes=objects, vectors=vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34106743",
   "metadata": {},
   "source": [
    "## Test Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame = 1\n",
    "last_frame = 20\n",
    "tracker = avstack.modules.tracking.tracker3d.BasicBoxTracker3D(check_reference=True)\n",
    "for frame in NSD.frames[first_frame:last_frame]:\n",
    "    ts = NSD.get_timestamp(frame)\n",
    "    ego = NSD.get_ego(frame)\n",
    "    img = NSD.get_image(frame, sensor=\"main_camera\")\n",
    "    objects = NSD.get_objects(frame, sensor=\"main_camera\")\n",
    "    detections = [avstack.modules.perception.detections.BoxDetection(\n",
    "                    'objects', obj.box3d, obj.reference, obj_type=obj.obj_type) for obj in objects]\n",
    "    tracks = tracker(t=ts, frame=frame, detections=detections, platform=ego.as_reference())\n",
    "    if frame > 1:\n",
    "        avapi.visualize.snapshot.show_image_with_boxes(img, tracks, inline=True, show_IDs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410c859",
   "metadata": {},
   "source": [
    "## Test Radar Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fff538",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_frame = 20\n",
    "tracker = avstack.modules.tracking.tracker3d.BasicRazelTracker(threshold_confirmed=2, assign_radius=10)\n",
    "for frame in NSD.frames[:last_frame]:\n",
    "    ts = NSD.get_timestamp(frame)\n",
    "    radar = NSD.get_radar(frame)\n",
    "    ego = NSD.get_ego(frame)\n",
    "    objects = NSD.get_objects(frame)\n",
    "    img = NSD.get_image(frame, \"main_camera\")\n",
    "    detections = [avstack.modules.perception.detections.RazelDetection(\n",
    "                    radar.source_identifier, radar.data[i,:3], radar.reference)\n",
    "                  for i in range(radar.data.shape[0])]\n",
    "    detections = [det for det in detections if det.xyz[0] > 0]\n",
    "    tracks = tracker(t=ts, frame=frame, detections=detections, platform=radar.reference)\n",
    "    if frame > 1:\n",
    "        avapi.visualize.snapshot.show_image_with_boxes(img, tracks, inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 6\n",
    "pc = NSD.get_lidar(frame=frame)\n",
    "pc.data = np.zeros((0,4))\n",
    "objects = NSD.get_objects(frame=frame)\n",
    "rad = NSD.get_radar(frame=frame)\n",
    "det_xyz = avstack.geometry.transformations.matrix_spherical_to_cartesian(rad.data)\n",
    "\n",
    "# -- vectors from detections\n",
    "vectors = [obj.velocity_head_tail for obj in objects]\n",
    "avapi.visualize.snapshot.show_lidar_bev_with_boxes(pc, boxes=objects, vectors=vectors)\n",
    "\n",
    "# -- vectors from tracks\n",
    "# vectors = [obj.velocity_head_tail for obj in tracks]\n",
    "# avapi.visualize.snapshot.show_lidar_bev_with_boxes(pc, boxes=tracks, vectors=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cdca90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
